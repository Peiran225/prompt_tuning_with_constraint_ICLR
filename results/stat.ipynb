{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_path = '/root/projects/prompt_tuning_with_constraint_ICLR/results/FacebookAI'\n",
    "\n",
    "bert_path = '/root/projects/prompt_tuning_with_constraint_ICLR/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roberta-large', 'roberta-base']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>layer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.567212</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-2</td>\n",
       "      <td>trec_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.206155</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-2</td>\n",
       "      <td>trec_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.030909</td>\n",
       "      <td>0.674</td>\n",
       "      <td>-2</td>\n",
       "      <td>trec_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.539009</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-1</td>\n",
       "      <td>trec_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.112942</td>\n",
       "      <td>0.654</td>\n",
       "      <td>-1</td>\n",
       "      <td>trec_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  eval_loss  eval_accuracy  layer  prompt\n",
       "0    1.0   1.567212          0.444     -2  trec_2\n",
       "1    2.0   1.206155          0.546     -2  trec_2\n",
       "2    3.0   1.030909          0.674     -2  trec_2\n",
       "3    1.0   1.539009          0.460     -1  trec_2\n",
       "4    2.0   1.112942          0.654     -1  trec_2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'/root/projects/prompt_tuning_with_constraint_ICLR/results/FacebookAI/roberta-base/newprompt/trec_2__trec-gamma-5e-07-lr-0.001-lr_LM-0.001-epoch-3-num_of_init_text-1-seed-50similarityNone-layer--3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['layer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    u = len(df['layer'].unique())\n",
    "    return df, u\n",
    "from collections import defaultdict\n",
    "\n",
    "task_baselinse = {\n",
    "    'SST-2': 0.878,\n",
    "    'sst-5': 0.477,\n",
    "    'subj': 0.932,\n",
    "    'trec': 0.804,\n",
    "}\n",
    "def read_files(model_name, task_name, result_path=bert_path, multi=1):\n",
    "    file_names = []\n",
    "    all_files = os.listdir(f'{result_path}/{model_name}')\n",
    "    layer_num = 0\n",
    "    file_count = 0\n",
    "    all_layer_dict = {}\n",
    "    dict2 = defaultdict(list)\n",
    "\n",
    "    for file in all_files:\n",
    "        filename = f'{result_path}/{model_name}/{file}'\n",
    "        if task_name not in file:\n",
    "            continue\n",
    "        df, layer_num = read_csv(filename)\n",
    "        print(df.shape, layer_num)\n",
    "        file_count += 1\n",
    "        for i in range(0, layer_num):\n",
    "            i2 = (i+1)*multi-1\n",
    "            delta = df['eval_accuracy'][i2] - task_baselinse[task_name]#- df['eval_accuracy'][0]\n",
    "            # print(i2, i , delta)\n",
    "            dict2[df['layer'][i2]].append(delta - task_baselinse[task_name])\n",
    "            if not all_layer_dict.get(df['layer'][i2]):\n",
    "                all_layer_dict[df['layer'][i2]] = delta\n",
    "            else:\n",
    "                if delta > all_layer_dict[df['layer'][i2]]:\n",
    "                    all_layer_dict[df['layer'][i2]] = delta\n",
    "    \n",
    "    for k, v in dict2.items():\n",
    "        dict2[k] = np.std(v)\n",
    "\n",
    "    return all_layer_dict, file_count, dict2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5) 2\n",
      "(14, 5) 14\n",
      "(14, 5) 14\n",
      "(14, 5) 14\n",
      "(14, 5) 14\n",
      "(14, 5) 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({-2: 0.006174311926605447,\n",
       "  -1: -0.0007064220183485848,\n",
       "  0: -0.0007064220183485848,\n",
       "  1: -0.006440366972477074,\n",
       "  2: -0.0018532110091743492,\n",
       "  3: 0.0015871559633027221,\n",
       "  4: -0.0018532110091743492,\n",
       "  5: -0.0007064220183485848,\n",
       "  6: -0.004146788990825656,\n",
       "  7: -0.0007064220183485848,\n",
       "  8: -0.0075871559633027275,\n",
       "  9: -0.006440366972477074,\n",
       "  10: -0.0075871559633027275,\n",
       "  11: -0.0075871559633027275},\n",
       " 6,\n",
       " defaultdict(list,\n",
       "             {-2: 0.024452883167766764,\n",
       "              -1: 0.02296840823891848,\n",
       "              0: 0.006380930157451167,\n",
       "              1: 0.004789131426105762,\n",
       "              2: 0.0069794147039921655,\n",
       "              3: 0.007410777257524537,\n",
       "              4: 0.0073751996288135375,\n",
       "              5: 0.00704692270446662,\n",
       "              6: 0.0037407124840137793,\n",
       "              7: 0.00633957567022259,\n",
       "              8: 0.004506165757887283,\n",
       "              9: 0.003932667018229871,\n",
       "              10: 0.002655008463942711,\n",
       "              11: 0.0038652063179707968}))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('bert-base-uncased', 'SST-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-2: -0.044665758401453204,\n",
       "  -1: -0.041032697547683905,\n",
       "  0: -0.0482988192552225,\n",
       "  1: -0.052840145322434195,\n",
       "  2: -0.05828973660308806,\n",
       "  3: -0.05465667574931876,\n",
       "  4: -0.05102361489554946,\n",
       "  5: -0.066464123524069,\n",
       "  6: -0.05828973660308806,\n",
       "  7: -0.047390554041780164,\n",
       "  8: -0.0591980018165304,\n",
       "  9: -0.05465667574931876,\n",
       "  10: -0.06010626702997279,\n",
       "  11: -0.05374841053587648},\n",
       " 5,\n",
       " defaultdict(list,\n",
       "             {-2: 0.057874670803748036,\n",
       "              -1: 0.03998595695913344,\n",
       "              0: 0.035337937117606806,\n",
       "              1: 0.0363151647465612,\n",
       "              2: 0.03428674113131578,\n",
       "              3: 0.03466195197177382,\n",
       "              4: 0.034716172987185705,\n",
       "              5: 0.03464766918071135,\n",
       "              6: 0.031413898862048824,\n",
       "              7: 0.03489157295402222,\n",
       "              8: 0.034010378707635326,\n",
       "              9: 0.036699309861360635,\n",
       "              10: 0.031675415635379095,\n",
       "              11: 0.033913217102675176}))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('bert-base-uncased', 'sst-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-2: 0.013499999999999956,\n",
       "  -1: 0.010499999999999954,\n",
       "  0: 0.010999999999999899,\n",
       "  1: 0.010999999999999899,\n",
       "  2: 0.012499999999999956,\n",
       "  3: 0.011499999999999955,\n",
       "  4: 0.009499999999999953,\n",
       "  5: 0.010499999999999954,\n",
       "  6: 0.010499999999999954,\n",
       "  7: 0.010499999999999954,\n",
       "  8: 0.008499999999999952,\n",
       "  9: 0.008999999999999897,\n",
       "  10: 0.010999999999999899,\n",
       "  11: 0.0119999999999999},\n",
       " 5,\n",
       " defaultdict(list,\n",
       "             {-2: 0.01315446692192428,\n",
       "              -1: 0.0025377155080898994,\n",
       "              0: 0.012095453691366826,\n",
       "              1: 0.012019151384353203,\n",
       "              2: 0.012452309022827837,\n",
       "              3: 0.011565465835840758,\n",
       "              4: 0.0119899958298575,\n",
       "              5: 0.01155248890932166,\n",
       "              6: 0.011659331027121564,\n",
       "              7: 0.01148738438461948,\n",
       "              8: 0.011289818421923338,\n",
       "              9: 0.01144290172989349,\n",
       "              10: 0.011842297074469944,\n",
       "              11: 0.012255610959882797}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('bert-base-uncased', 'subj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-1: 0.20400000000000001,\n",
       "  0: 0.04999999999999999,\n",
       "  1: 0.04999999999999999,\n",
       "  2: 0.04999999999999999,\n",
       "  3: 0.04999999999999999,\n",
       "  4: 0.04999999999999999,\n",
       "  5: 0.04999999999999999,\n",
       "  6: 0.04999999999999999,\n",
       "  7: 0.04999999999999999,\n",
       "  8: 0.04999999999999999,\n",
       "  9: 0.04999999999999999,\n",
       "  10: 0.04999999999999999,\n",
       "  11: 0.04999999999999999},\n",
       " 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('bert-base-uncased', 'trec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-2: 0.039431192660550396,\n",
       "  -1: 0.03484403669724756,\n",
       "  0: 0.035990825688073436,\n",
       "  1: 0.03369724770642202,\n",
       "  2: 0.0314036697247706,\n",
       "  3: 0.03484403669724756,\n",
       "  4: 0.039431192660550396,\n",
       "  5: 0.035990825688073436,\n",
       "  6: 0.03369724770642202,\n",
       "  7: 0.035990825688073436,\n",
       "  8: 0.03828440366972474,\n",
       "  9: 0.035990825688073436,\n",
       "  10: 0.035990825688073436,\n",
       "  11: 0.0371376146788992},\n",
       " 1,\n",
       " defaultdict(list,\n",
       "             {-2: 0.0,\n",
       "              -1: 0.0,\n",
       "              0: 0.0,\n",
       "              1: 0.0,\n",
       "              2: 0.0,\n",
       "              3: 0.0,\n",
       "              4: 0.0,\n",
       "              5: 0.0,\n",
       "              6: 0.0,\n",
       "              7: 0.0,\n",
       "              8: 0.0,\n",
       "              9: 0.0,\n",
       "              10: 0.0,\n",
       "              11: 0.0}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('roberta-base', 'SST-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-2: -0.0737302452316076,\n",
       "  -1: -0.026500454132606766,\n",
       "  0: -0.0737302452316076,\n",
       "  1: -0.01741780199818349,\n",
       "  2: -0.0482988192552225,\n",
       "  3: -0.040124432334241567,\n",
       "  4: -0.037399636693914606,\n",
       "  5: -0.031041780199818403,\n",
       "  6: -0.028316984559491387,\n",
       "  7: -0.07282198001816537,\n",
       "  8: -0.0591980018165304,\n",
       "  9: -0.09280381471389648,\n",
       "  10: -0.023775658492279805,\n",
       "  11: -0.06464759309718437},\n",
       " 2,\n",
       " defaultdict(list,\n",
       "             {-2: 0.06939764394148253,\n",
       "              -1: 0.08054536789872241,\n",
       "              0: 0.06980589213780018,\n",
       "              1: 0.08941992880965925,\n",
       "              2: 0.07245783424182924,\n",
       "              3: 0.08272141744347372,\n",
       "              4: 0.08608897810043806,\n",
       "              5: 0.08507794587949648,\n",
       "              6: 0.08196670717655058,\n",
       "              7: 0.07044115780232979,\n",
       "              8: 0.07307255655119342,\n",
       "              9: 0.05870794772458606,\n",
       "              10: 0.08605490032449603,\n",
       "              11: 0.06510993995642315}))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('roberta-base', 'sst-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({-2: 0.011499999999999955,\n",
       "  -1: 0.0129999999999999,\n",
       "  0: 0.013999999999999901,\n",
       "  1: 0.015999999999999903,\n",
       "  2: 0.009999999999999898,\n",
       "  3: 0.012499999999999956,\n",
       "  4: 0.0129999999999999,\n",
       "  5: 0.0129999999999999,\n",
       "  6: 0.009499999999999953,\n",
       "  7: 0.013499999999999956,\n",
       "  8: 0.010499999999999954,\n",
       "  9: 0.013499999999999956,\n",
       "  10: 0.011499999999999955,\n",
       "  11: 0.015499999999999958},\n",
       " 3,\n",
       " defaultdict(list,\n",
       "             {-2: 0.007675719293112976,\n",
       "              -1: 0.006357410374253518,\n",
       "              0: 0.0127401923062409,\n",
       "              1: 0.011855612829185807,\n",
       "              2: 0.013795127964450194,\n",
       "              3: 0.016781479540122664,\n",
       "              4: 0.008757932911874145,\n",
       "              5: 0.012591884511682727,\n",
       "              6: 0.014174507634012084,\n",
       "              7: 0.01217494010936672,\n",
       "              8: 0.01474128744565939,\n",
       "              9: 0.011440668201153659,\n",
       "              10: 0.010678704145270728,\n",
       "              11: 0.01233445940805227}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('roberta-base', 'subj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 5) 14\n",
      "(81, 5) 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({-2: -0.016509536784741097,\n",
       "  -1: -0.0019772933696639017,\n",
       "  0: -0.016509536784741097,\n",
       "  1: -0.00016076294277928005,\n",
       "  2: -0.03285831062670297,\n",
       "  3: -0.031950045413260686,\n",
       "  4: -0.02559218891916437,\n",
       "  5: -0.021959128065395073,\n",
       "  6: -0.027408719346049104,\n",
       "  7: -0.043757493188010865,\n",
       "  8: -0.0419409627611263,\n",
       "  9: -0.031950045413260686,\n",
       "  10: -0.03376657584014536,\n",
       "  11: -0.03376657584014536},\n",
       " 2,\n",
       " defaultdict(list,\n",
       "             {-2: 0.002724795640326988,\n",
       "              -1: 0.013272970158512285,\n",
       "              0: 0.0021408016384697483,\n",
       "              1: 0.01798273376314565,\n",
       "              2: 0.006422404915409193,\n",
       "              3: 0.005994244587715192,\n",
       "              4: 0.0004281603276939497,\n",
       "              5: 0.015894641235240675,\n",
       "              6: 0.0,\n",
       "              7: 0.0,\n",
       "              8: 0.0,\n",
       "              9: 0.0,\n",
       "              10: 0.0,\n",
       "              11: 0.0}))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('roberta-base/newprompt', 'sst-5', roberta_path, multi=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 5) 14\n",
      "(42, 5) 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({-2: -0.118,\n",
       "  -1: -0.04200000000000004,\n",
       "  0: -0.08400000000000007,\n",
       "  1: -0.09800000000000009,\n",
       "  2: -0.1140000000000001,\n",
       "  3: -0.05800000000000005,\n",
       "  4: -0.03200000000000003,\n",
       "  5: -0.10200000000000009,\n",
       "  6: -0.09800000000000009,\n",
       "  7: -0.1100000000000001,\n",
       "  8: -0.09400000000000008,\n",
       "  9: -0.134,\n",
       "  10: -0.050000000000000044,\n",
       "  11: -0.17800000000000005},\n",
       " 2,\n",
       " defaultdict(list,\n",
       "             {-2: 0.006000000000000005,\n",
       "              -1: 0.03700000000000003,\n",
       "              0: 0.043999999999999984,\n",
       "              1: 0.01899999999999996,\n",
       "              2: 0.0019999999999999463,\n",
       "              3: 0.0050000000000000044,\n",
       "              4: 0.05299999999999999,\n",
       "              5: 0.006000000000000005,\n",
       "              6: 0.0040000000000000036,\n",
       "              7: 0.03899999999999998,\n",
       "              8: 0.030999999999999972,\n",
       "              9: 0.04299999999999998,\n",
       "              10: 0.020000000000000018,\n",
       "              11: 0.0040000000000000036}))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files('roberta-base/newprompt', 'trec', roberta_path, multi=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_words(text):\n",
    "\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'entity', 'expression', 'human', 'location', 'number']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text = ['Description', 'Entity', 'Expression', 'Human', 'Location', 'Number']\n",
    "   \n",
    "verbalizer_dict = [k.lower() for k in label_text]\n",
    "verbalizer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2461967731.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[74], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    for word in extract_words('Expression Expression Exp'.lower()):\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "for word in extract_words('Expression Expression Exp'.lower()):\n",
    "    if word in verbalizer_dict:\n",
    "        tmp = word\n",
    "        break\n",
    "if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expression expression exp'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Expression Expression Exp'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
